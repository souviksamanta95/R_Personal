d1 %>% filter(Crop=="Rice") %>% group_by(State = State_Name) %>%
summarize(Total = sum(Production)) %>% arrange(desc(Total))
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(Production))+
geom_histogram(color="black",aes(fill=Season)) + theme_classic()+
facet_grid(District_Name~., scales = "free")
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(Production))+
geom_histogram(color="black",aes(fill=District_Name)) + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(Production, District_Name))+
geom_histogram(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(x=Production, y=District_Name))+
geom_histogram(color="black") + theme_classic()
ggplot(aes(x=Production, y=factor(District_Name))+
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(x=Production, y=factor(District_Name)))+
geom_histogram(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(x=Production, y=as.factor(District_Name)))+
geom_histogram(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(x=Production, y=as.factor(District_Name)))+
geom_point(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(x=Production, y=as.factor(District_Name)))+
geom_line(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(x=Production, y=as.factor(District_Name)))+
geom_smooth(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(y=Production, x=as.factor(District_Name)))+
geom_smooth(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(y=Production, x=as.factor(District_Name)))+
geom_bar(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(y=Production, x=District_Name))+
geom_bar(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(Production))+
geom_bar(color="black") + theme_classic()
class(d1$District_Name)
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(x=factor(District_Name),y=Production))+
geom_bar(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(x=factor(District_Name),y=Production))+
geom_area(color="black") + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(x=factor(District_Name),y=Production))+
geom_area() + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(Production))+
geom_area() + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(Production,count))+
geom_area() + theme_classic()
d1 %>% filter(Crop_Year==2005,Crop=="Rice",State_Name=="Bihar") %>%
ggplot(aes(Production))+
geom_bar() + theme_classic()
plot(rice_new)
sum(is.na(yrr_rice))
# Year wise missing values - in the data we can see so many missing values in 2015, so we should remove record for 2015 which is the last row
nrow(yrr_rice)
yrr_rice <- yrr_rice[-19,]
# State wise missing values ---
sapply(yrr_rice, function(x)sum(is.na(x)))
rice_new <- yrr_rice %>% select(-`Andaman and Nicobar Islands`,-Jharkhand)
sum(is.na(rice_new))
sapply(rice_new, function(x)sum(is.na(x)))
library(imputeTS)
rice_new <- na_mean(rice_new)
sum(is.na(rice_new))
plot(rice_new)
plot(rice_new)
?spread
?gather
rice_str <- gather(rice_new, key = "State_Name", value = "Total_Production" )
rice_str
View(rice_str)
rice_str <- gather(rice_new, key = "Year", value = "Total_Production",c(-State_Name) )
rice_str <- gather(rice_new, key = "Year", value = "Total_Production",c(-Crop_Year))
ggplot(rice_str, aes(x=Crop_Year,y=Total_Production))
ggplot(rice_str, aes(x=Crop_Year,y=Total_Production))+
geom_bar(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=Total_Production))+
geom_histogram(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=factor(Total_Production)))+
geom_histogram(color="black") + theme_classic()
ggplot(rice_str, aes(Total_Production)+
ggplot(rice_str, aes(Total_Production))+
geom_histogram(color="black") + theme_classic()
ggplot(rice_str, aes(Total_Production))+
geom_histogram(color="black") + theme_classic()
rice_str <- gather(rice_new, key = "State_Name", value = "Total_Production",c(-Crop_Year))
ggplot(rice_str, aes(Total_Production,Crop_Year))+
geom_histogram(color="black") + theme_classic()
ggplot(rice_str, aes(Total_Production,Crop_Year))+
geom_step(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=Total_Production))+
geom_step(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=Total_Production))+
geom_bar(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=Total_Production))+
geom_point(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=Total_Production,size = Total_Production))+
geom_point(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=sum(Total_Production)))+
geom_bar(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=State_Name))+
geom_bar(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=State_Name))+
geom_point(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=State_Name, size=Total_Production))+
geom_point(color="black") + theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=State_Name, size=Total_Production, color = State_Name))+
geom_point() + theme_classic()
rice_str %>% filter(Crop=="Bihar") %>%
ggplot(aes(Total_Production, color=Crop_Year))+
geom_point() + theme_classic()
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(Total_Production, color=Crop_Year))+
geom_point() + theme_classic()
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(Total_Production, color=Crop_Year))+
geom_bar() + theme_classic()
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(x=Crop_Year,y=Total_Production))+
geom_bar() + theme_classic()
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(x=Crop_Year,y=Total_Production))+
geom_bar(stat=identify()) + theme_classic()
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(Crop_Year,Total_Production))+
geom_bar(stat="identify") + theme_classic()
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(Crop_Year,Total_Production))+
geom_bar(stat="identity") + theme_classic()
rice_str <- gather(rice_new, key = "State_Name", value = "Production",c(-Crop_Year))
rice_str %>% group_by(State = State_Name) %>%
summarize(Total = sum(Production)) %>% arrange(desc(Total))
# Year-wise rice production for Bihar -
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(Crop_Year,Production))+
geom_bar(stat="identity", color="black", fill = "blue") + theme_classic()
# Year-wise rice production for Bihar -
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(Crop_Year,Production))+
geom_bar(stat="identity", color="black", fill = "light blue") + theme_classic()
# Year-wise rice production for Bihar -
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(Crop_Year,Production))+
geom_bar(stat="identity", color="black", fill = "light blue") +
ggtitle("Year-wise rice production for Bihar") +
theme_classic()
# Year-wise rice production for Bihar -
rice_str %>% filter(State_Name=="Bihar") %>%
ggplot(aes(Crop_Year,Production))+
geom_bar(stat="identity", color="black", fill = "light blue") +
ggtitle("Year-wise rice production for Bihar") +
theme_classic()
# Year-wise rice production for Uttar Pradesh -
rice_str %>% filter(State_Name=="Uttar Pradesh") %>%
ggplot(aes(Crop_Year,Production))+
geom_bar(stat="identity", color="black", fill = "light blue") +
ggtitle("Year-wise rice production for Uttar Pradesh") +
theme_classic()
# Year-wise rice production for Assam -
rice_str %>% filter(State_Name=="Assam") %>%
ggplot(aes(Crop_Year,Production))+
geom_bar(stat="identity", color="black", fill = "light blue") +
ggtitle("Year-wise rice production for Assam") +
theme_classic()
# Year-wise rice production for Odisha -
rice_str %>% filter(State_Name=="Odisha") %>%
ggplot(aes(Crop_Year,Production))+
geom_bar(stat="identity", color="black", fill = "light blue") +
ggtitle("Year-wise rice production for Odisha") +
theme_classic()
# Year-wise rice production for Karnataka -
rice_str %>% filter(State_Name=="Karnataka") %>%
ggplot(aes(Crop_Year,Production))+
geom_bar(stat="identity", color="black", fill = "light blue") +
ggtitle("Year-wise rice production for Karnataka") +
theme_classic()
ggplot(rice_str, aes(x=Crop_Year,y=State_Name, size=Total_Production, color = State_Name))+
geom_point() + theme_classic()
d1 <- read.csv("C:/Users/souvi/Documents/R/IM507/apy.csv")
#View(d1)
head(d1)
dim(d1)
names(d1)
summary(d1)
str(d1)
class(d1$Production)
# Class of Production has been taken as factor which needs to be converted to double
d1$Production <- as.double(d1$Production)
str(d1)
class(d1$Production)
typeof(d1$Production)
#Check for missing values -----
sum(is.na(d1))
library(dplyr)
library(tidyr)
d_year <- d1 %>% group_by(Crop_Year,State_Name)%>%
summarize(Total_Production = sum(Production))
yrr <- spread(d_year, key = "State_Name", value = "Total_Production" )
y_2005 <- d1 %>% filter(Crop_Year==2005)
y_2005 <- d1 %>% filter(Crop_Year==2005)
y_2005_crop <- y_2005 %>% group_by(Crop = Crop) %>%
summarize(Total = sum(Production)) %>% arrange(desc(Total))
head(y_2005_crop)
rice <- d1 %>% filter(Crop=="Rice")
rice_state <- rice %>% group_by(Crop_Year,State_Name)%>%
summarize(Total_Production = sum(Production))
yrr_rice <- spread(rice_state, key = "State_Name", value = "Total_Production" )
dim(yrr_rice)
sum(is.na(yrr_rice))
# Year wise missing values - in the data we can see so many missing values in 2015, so we should remove record for 2015 which is the last row
nrow(yrr_rice)
yrr_rice <- yrr_rice[-19,]
# State wise missing values ---
sapply(yrr_rice, function(x)sum(is.na(x)))
rice_new <- yrr_rice %>% select(-`Andaman and Nicobar Islands`,-Jharkhand)
sum(is.na(rice_new))
sapply(rice_new, function(x)sum(is.na(x)))
library(imputeTS)
rice_new <- na_mean(rice_new)
sum(is.na(rice_new))
library(ggplot2)
rice_str <- gather(rice_new, key = "State_Name", value = "Production",c(-Crop_Year))
View(y_2005)
install.packages(c("gains", "raster", "sandwich", "sp", "usdm"))
library(readr)
data <- read_csv(url("https://github.com/imi-insight/InSession/blob/master/Linear%20Regression/Datasets/multipleChoiceResponses.csv"))
View(data)
data <- read_csv(url("Linear Regression/Datasets/multipleChoiceResponses.csv"))
data <- read_csv(url("https://github.com/imi-insight/InSession/blob/master/Linear%20Regression/Datasets/multipleChoiceResponses.csv"))
View(data)
data <- read_csv(url("https://raw.githubusercontent.com/imi-insight/InSession/master/Linear%20Regression/Datasets/multipleChoiceResponses.csv"))
schema <- read_csv(url("https://raw.githubusercontent.com/imi-insight/InSession/master/Linear%20Regression/Datasets/schema.csv"))
knitr::opts_chunk$set(echo = TRUE)
cat("\014")    # to clear console to CTRL+L
rm(list=ls())
library(dplyr)
library (readr)
data<-read.csv(url("https://raw.githubusercontent.com/imi-insight/InSession/master/Linear%20Regression/Datasets/multipleChoiceResponses.csv"))
schema=read.csv(url("https://raw.githubusercontent.com/imi-insight/InSession/master/Linear%20Regression/Datasets/schema.csv"))
schema
names(schema)
levels(as.factor(schema$Asked))
library(sqldf)
col=data.frame(sqldf("Select Column from schema where Asked = 'All'"))
col_all=col[,1]
col_all
library(dplyr)
cols=c("GenderSelect","Country","Age","EmploymentStatus","StudentStatus",
"LearningDataScience","CodeWriter","CareerSwitcher",
"CurrentJobTitleSelect","CurrentEmployerType","MLToolNextYearSelect",
"MLMethodNextYearSelect","LanguageRecommendationSelect","PublicDatasetsSelect","LearningPlatformSelect",
"LearningPlatformUsefulnessArxiv","LearningPlatformUsefulnessBlogs","LearningPlatformUsefulnessCollege",
"LearningPlatformUsefulnessCompany","LearningPlatformUsefulnessConferences","LearningPlatformUsefulnessFriends",
"LearningPlatformUsefulnessKaggle","LearningPlatformUsefulnessNewsletters","LearningPlatformUsefulnessCommunities",
"LearningPlatformUsefulnessDocumentation","LearningPlatformUsefulnessCourses","LearningPlatformUsefulnessProjects",
"LearningPlatformUsefulnessPodcasts","LearningPlatformUsefulnessSO","LearningPlatformUsefulnessTextbook",
"LearningPlatformUsefulnessTradeBook","LearningPlatformUsefulnessTutoring","LearningPlatformUsefulnessYouTube",
"BlogsPodcastsNewslettersSelect","LearningDataScienceTime","JobSkillImportanceBigData","JobSkillImportanceDegree",
"JobSkillImportanceStats","JobSkillImportanceEnterpriseTools","JobSkillImportancePython","JobSkillImportanceR",
"JobSkillImportanceSQL","JobSkillImportanceKaggleRanking","JobSkillImportanceMOOC","JobSkillImportanceVisualizations",
"HardwarePersonalProjectsSelect","TimeSpentStudying","ProveKnowledgeSelect","DataScienceIdentitySelect",
"FormalEducation","MajorSelect","Tenure","PastJobTitlesSelect","FirstTrainingSelect","LearningCategorySelftTaught",
"LearningCategoryOnlineCourses","LearningCategoryWork","LearningCategoryUniversity","LearningCategoryKaggle",
"MLSkillsSelect","MLTechniquesSelect","ParentsEducation","EmployerIndustry","EmployerSize","EmployerSizeChange",
"EmployerMLTime","EmployerSearchMethod","UniversityImportance","JobFunctionSelect","WorkHardwareSelect",
"WorkDataTypeSelect","WorkProductionFrequency","WorkDatasetSize","WorkAlgorithmsSelect","WorkToolsSelect",
"WorkToolsFrequencyAmazonML","WorkToolsFrequencyAWS","WorkToolsFrequencyAngoss","WorkToolsFrequencyC","WorkToolsFrequencyCloudera",
"WorkToolsFrequencyDataRobot","WorkToolsFrequencyFlume","WorkToolsFrequencyGCP","WorkToolsFrequencyHadoop","WorkToolsFrequencyIBMCognos",
"WorkToolsFrequencyIBMSPSSModeler","WorkToolsFrequencyIBMSPSSStatistics","WorkToolsFrequencyIBMWatson","WorkToolsFrequencyImpala",
"WorkToolsFrequencyJava","WorkToolsFrequencyJulia","WorkToolsFrequencyJupyter","WorkToolsFrequencyKNIMECommercial","WorkToolsFrequencyKNIMEFree",
"WorkToolsFrequencyMathematica","WorkToolsFrequencyMATLAB","WorkToolsFrequencyAzure","WorkToolsFrequencyExcel",
"WorkToolsFrequencyMicrosoftRServer","WorkToolsFrequencyMicrosoftSQL","WorkToolsFrequencyMinitab","WorkToolsFrequencyNoSQL",
"WorkToolsFrequencyOracle","WorkToolsFrequencyOrange","WorkToolsFrequencyPerl","WorkToolsFrequencyPython",
"WorkToolsFrequencyQlik","WorkToolsFrequencyR","WorkToolsFrequencyRapidMinerCommercial","WorkToolsFrequencyRapidMinerFree",
"WorkToolsFrequencySalfrod","WorkToolsFrequencySAPBusinessObjects","WorkToolsFrequencySASBase","WorkToolsFrequencySASEnterprise",
"WorkToolsFrequencySASJMP","WorkToolsFrequencySpark","WorkToolsFrequencySQL","WorkToolsFrequencyStan",
"WorkToolsFrequencyStatistica","WorkToolsFrequencyTableau","WorkToolsFrequencyTensorFlow","WorkToolsFrequencyTIBCO",
"WorkToolsFrequencyUnix","WorkMethodsSelect","WorkMethodsFrequencyAssociationRules",
"WorkMethodsFrequencyBayesian","WorkMethodsFrequencyCNNs","WorkMethodsFrequencyCollaborativeFiltering",
"WorkMethodsFrequencyDataVisualization","WorkMethodsFrequencyDecisionTrees",
"WorkMethodsFrequencyEnsembleMethods","WorkMethodsFrequencyEvolutionaryApproaches","WorkMethodsFrequencyGANs","WorkMethodsFrequencyGBM","WorkMethodsFrequencyHMMs",
"WorkMethodsFrequencyKNN","WorkMethodsFrequencyLiftAnalysis","WorkMethodsFrequencyLogisticRegression","WorkMethodsFrequencyMLN","WorkMethodsFrequencyNaiveBayes",
"WorkMethodsFrequencyNLP","WorkMethodsFrequencyNeuralNetworks","WorkMethodsFrequencyPCA","WorkMethodsFrequencyPrescriptiveModeling",
"WorkMethodsFrequencyRandomForests","WorkMethodsFrequencyRecommenderSystems","WorkMethodsFrequencyRNNs",
"WorkMethodsFrequencySegmentation","WorkMethodsFrequencySimulation","WorkMethodsFrequencySVMs","WorkMethodsFrequencyTextAnalysis",
"WorkMethodsFrequencyTimeSeriesAnalysis","WorkMethodsFrequencySelect1","WorkMethodsFrequencySelect2","WorkMethodsFrequencySelect3",
"TimeGatheringData","TimeModelBuilding","TimeProduction","TimeVisualizing","TimeFindingInsights",
"AlgorithmUnderstandingLevel","WorkChallengesSelect","WorkChallengeFrequencyDeployment","CompensationAmount","CompensationCurrency")
useful_df=data %>% select(cols)
View(useful_df)
knitr::opts_chunk$set(echo = TRUE)
cat("\014")    # to clear console to CTRL+L
rm(list=ls())
library(dplyr)
library (readr)
data<-read.csv(url("https://raw.githubusercontent.com/imi-insight/InSession/master/Linear%20Regression/Datasets/multipleChoiceResponses.csv"))
schema=read.csv(url("https://raw.githubusercontent.com/imi-insight/InSession/master/Linear%20Regression/Datasets/schema.csv"))
schema
names(schema)
levels(as.factor(schema$Asked))
library(sqldf)
col=data.frame(sqldf("Select Column from schema where Asked = 'All'"))
col_all=col[,1]
col_all
library(dplyr)
cols=c("GenderSelect","Country","Age","EmploymentStatus","StudentStatus",
"LearningDataScience","CodeWriter","CareerSwitcher",
"CurrentJobTitleSelect","CurrentEmployerType","MLToolNextYearSelect",
"MLMethodNextYearSelect","LanguageRecommendationSelect","PublicDatasetsSelect","LearningPlatformSelect",
"LearningPlatformUsefulnessArxiv","LearningPlatformUsefulnessBlogs","LearningPlatformUsefulnessCollege",
"LearningPlatformUsefulnessCompany","LearningPlatformUsefulnessConferences","LearningPlatformUsefulnessFriends",
"LearningPlatformUsefulnessKaggle","LearningPlatformUsefulnessNewsletters","LearningPlatformUsefulnessCommunities",
"LearningPlatformUsefulnessDocumentation","LearningPlatformUsefulnessCourses","LearningPlatformUsefulnessProjects",
"LearningPlatformUsefulnessPodcasts","LearningPlatformUsefulnessSO","LearningPlatformUsefulnessTextbook",
"LearningPlatformUsefulnessTradeBook","LearningPlatformUsefulnessTutoring","LearningPlatformUsefulnessYouTube",
"BlogsPodcastsNewslettersSelect","LearningDataScienceTime","JobSkillImportanceBigData","JobSkillImportanceDegree",
"JobSkillImportanceStats","JobSkillImportanceEnterpriseTools","JobSkillImportancePython","JobSkillImportanceR",
"JobSkillImportanceSQL","JobSkillImportanceKaggleRanking","JobSkillImportanceMOOC","JobSkillImportanceVisualizations",
"HardwarePersonalProjectsSelect","TimeSpentStudying","ProveKnowledgeSelect","DataScienceIdentitySelect",
"FormalEducation","MajorSelect","Tenure","PastJobTitlesSelect","FirstTrainingSelect","LearningCategorySelftTaught",
"LearningCategoryOnlineCourses","LearningCategoryWork","LearningCategoryUniversity","LearningCategoryKaggle",
"MLSkillsSelect","MLTechniquesSelect","ParentsEducation","EmployerIndustry","EmployerSize","EmployerSizeChange",
"EmployerMLTime","EmployerSearchMethod","UniversityImportance","JobFunctionSelect","WorkHardwareSelect",
"WorkDataTypeSelect","WorkProductionFrequency","WorkDatasetSize","WorkAlgorithmsSelect","WorkToolsSelect",
"WorkToolsFrequencyAmazonML","WorkToolsFrequencyAWS","WorkToolsFrequencyAngoss","WorkToolsFrequencyC","WorkToolsFrequencyCloudera",
"WorkToolsFrequencyDataRobot","WorkToolsFrequencyFlume","WorkToolsFrequencyGCP","WorkToolsFrequencyHadoop","WorkToolsFrequencyIBMCognos",
"WorkToolsFrequencyIBMSPSSModeler","WorkToolsFrequencyIBMSPSSStatistics","WorkToolsFrequencyIBMWatson","WorkToolsFrequencyImpala",
"WorkToolsFrequencyJava","WorkToolsFrequencyJulia","WorkToolsFrequencyJupyter","WorkToolsFrequencyKNIMECommercial","WorkToolsFrequencyKNIMEFree",
"WorkToolsFrequencyMathematica","WorkToolsFrequencyMATLAB","WorkToolsFrequencyAzure","WorkToolsFrequencyExcel",
"WorkToolsFrequencyMicrosoftRServer","WorkToolsFrequencyMicrosoftSQL","WorkToolsFrequencyMinitab","WorkToolsFrequencyNoSQL",
"WorkToolsFrequencyOracle","WorkToolsFrequencyOrange","WorkToolsFrequencyPerl","WorkToolsFrequencyPython",
"WorkToolsFrequencyQlik","WorkToolsFrequencyR","WorkToolsFrequencyRapidMinerCommercial","WorkToolsFrequencyRapidMinerFree",
"WorkToolsFrequencySalfrod","WorkToolsFrequencySAPBusinessObjects","WorkToolsFrequencySASBase","WorkToolsFrequencySASEnterprise",
"WorkToolsFrequencySASJMP","WorkToolsFrequencySpark","WorkToolsFrequencySQL","WorkToolsFrequencyStan",
"WorkToolsFrequencyStatistica","WorkToolsFrequencyTableau","WorkToolsFrequencyTensorFlow","WorkToolsFrequencyTIBCO",
"WorkToolsFrequencyUnix","WorkMethodsSelect","WorkMethodsFrequencyAssociationRules",
"WorkMethodsFrequencyBayesian","WorkMethodsFrequencyCNNs","WorkMethodsFrequencyCollaborativeFiltering",
"WorkMethodsFrequencyDataVisualization","WorkMethodsFrequencyDecisionTrees",
"WorkMethodsFrequencyEnsembleMethods","WorkMethodsFrequencyEvolutionaryApproaches","WorkMethodsFrequencyGANs","WorkMethodsFrequencyGBM","WorkMethodsFrequencyHMMs",
"WorkMethodsFrequencyKNN","WorkMethodsFrequencyLiftAnalysis","WorkMethodsFrequencyLogisticRegression","WorkMethodsFrequencyMLN","WorkMethodsFrequencyNaiveBayes",
"WorkMethodsFrequencyNLP","WorkMethodsFrequencyNeuralNetworks","WorkMethodsFrequencyPCA","WorkMethodsFrequencyPrescriptiveModeling",
"WorkMethodsFrequencyRandomForests","WorkMethodsFrequencyRecommenderSystems","WorkMethodsFrequencyRNNs",
"WorkMethodsFrequencySegmentation","WorkMethodsFrequencySimulation","WorkMethodsFrequencySVMs","WorkMethodsFrequencyTextAnalysis",
"WorkMethodsFrequencyTimeSeriesAnalysis","WorkMethodsFrequencySelect1","WorkMethodsFrequencySelect2","WorkMethodsFrequencySelect3",
"TimeGatheringData","TimeModelBuilding","TimeProduction","TimeVisualizing","TimeFindingInsights",
"AlgorithmUnderstandingLevel","WorkChallengesSelect","WorkChallengeFrequencyDeployment","CompensationAmount","CompensationCurrency")
useful_df=data %>% select(cols)
getwd()
setwd("C:/Users/souvi/Documents/R/BA/KNN")
movies <-  read.csv("movies.csv")
str(movies)
head(movies)
View(movies)
summary(movies)
# KNN Imputation
# KNN is present in VIM Package
install.packages("VIM")
# KNN Imputation
# KNN is present in VIM Package
# install.packages("VIM")
library("VIM")
?KNN
?KNN()
# Impute the missing values in some variables
movie1 <- KNN(movies, variable = "Genre", "Profitability", k=6)
# Impute the missing values in some variables
movie1 <- kNN(movies, variable = "Genre", "Profitability", k=6)
?kNN()
summary(movie1)
movie2 <- kNN(movies)
summary(movie2)
str(movies)
summary(movies)
summary(movie2)
head(movie2)
# Clening additional variables (Junk)
movies2 <- subset(movies2, select = Film:Year)
head(movies2)
head(movie2)
View(movie2)
# Impute the missing values in some variables
movie1 <- kNN(movies, variable = "Genre", "Profitability", k=6)
View(movie1)
# Clening additional variables (Junk)
movies2 <- subset(movies2, select = Film:Year)
# Clening additional variables (Junk)
movies2 <- subset(movies2, select = "Film:Year")
# Clening additional variables (Junk)
movies2 <- subset(movie2, select = Film:Year)
head(movie2)
# Clening additional variables (Junk)
movie2 <- subset(movie2, select = Film:Year)
head(movie2)
getwd()
setwd("C:/Users/souvi/Documents/R/BA/KNN")
movies <-  read.csv("movies.csv")
str(movies)
head(movies)
summary(movies)
# KNN Imputation
# KNN is present in VIM Package
# install.packages("VIM")
library("VIM")
?kNN()
# Impute the missing values in some variables
movie1 <- kNN(movies, variable = "Genre", "Profitability", k=6)
summary(movie1)
movie2 <- kNN(movies)
summary(movie2)
head(movie2)
# Clening additional variables (Junk)
movie2 <- subset(movie2, select = Film:Year)
head(movie2)
movie2 <- kNN(movies)
# Clening additional variables (Junk)
movie2 <- subset(movie2, select = Film:Year)
attach(LungCapData2)
lung <- read.csv("LungCapData2.csv")
View(lung)
names(lung)
class(Age)
class(lung$Age)
library(dplyr)
lung %>%
class(Age)
library(ggplot2)
ggplot(lung, aes(x=LungCap, y=Age))+
geom_point()
cor(lung$Age,lung$LungCap)
?lm
mod <- lm(lung$LungCap ~ lung$Age)  # Always put the dependent variable inthe front
summary(mod)
ggplot(lung, aes(x=LungCap, y=Age))+
geom_point()
ggplot(lung, aes(x=LungCap, y=Age))+
geom_point()+geom_smooth()
attach(lung)
attributes(mod)
summary(mod)
#extracting the attrubutes
mod$coefficients
coef(mod)  #alternatively
#cheacking the plot of the model
plot(Age, LungCap, main = "Scatterplot")
abline(mod, col= "red", lwd =3)
#creating confidence level
conflict(mod)
#creating confidence level
conflict(mod)
#charging the level of significance
conflict(mod, level = 0.99)
#charging the level of significance
confint(mod, level = 0.99)
#creating confidence level
confint(mod)
#charging the level of significance
confint(mod, level = 0.99)
#summary model
summary(mod)
#analysis of variance for the model
anova(mod)
creating confidence level
confint(mod)
#charging the level of significance
confint(mod, level = 0.95)
#summary model
summary(mod)
#analysis of variance for the model
anova(mod)
#extracting the attrubutes
mod$coefficients
coef(mod)  #alternatively
#checking the plot of the model
plot(Age, LungCap, main = "Scatterplot")
abline(mod, col= "red", lwd =3)
#creating confidence level
confint(mod)
#charging the level of significance
confint(mod, level = 0.95)
#charging the level of significance
confint(mod, level = 0.99)
#summary model
summary(mod)
#analysis of variance for the model
anova(mod)
mform = c(2,2)
plot(mod)
mform = c(2,2)
plot(mod)
cor(lung$Age,lung$Height)
# Multiple Regression
model1 <- lm(lung$LungCap ~ lung$Age + lung$Height)
summary(model1)
plot(model1)
cor(lung$Age,lung$Height)
model2 <- lm(lung$LungCap ~ .,data = lung)
# Stepwise regression
model3 <- lm(lung$LungCap ~ 1,data = lung) # 1 means only intercept
summary(model3)
step(model3, direction = 'forward', scope = formula(model2))
step(model2, direction = "backward")
